---
layout: post
title: "AMD ROCmè¿è¡ŒLlama"
date: 2024-08-22 21:12:21 +0800
categories: æŠ€æœ¯
tags: AI å¤§æ¨¡å‹ Llama ROCm
---

> æˆ‘åœ¨å®‰è£…çš„æ—¶å€™`ROCm`æœ€æ–°ç‰ˆæœ¬ä¸º6.2ï¼Œæœ¬æ–‡æ“ä½œéƒ½åŸºäº **Ubuntu 24.04 LTS** å’Œ **ROCm 6.2**

å½“åˆè£…æœºä¸ºäº†(é»‘è‹¹æœ)ä¸€ç›´é€‰æ‹©AMDæ˜¾å¡ï¼Œç°åœ¨æAIä¸€æä¸€ä¸ªä¸å±å£°ã€‚æ—©çŸ¥é“æŠ•å…¥è€é»„çš„æ€€æŠ±äº†ï¼Œç°åœ¨çš„Nå¡æ›´åŠ è®©æˆ‘é«˜æ”€ä¸èµ·ğŸ˜­

æˆ‘çš„æ˜¾å¡æ˜¯ `6800XT`, ä¸€å¼€å§‹æˆ‘æ˜¯åœ¨MacOSç³»ç»Ÿä¸Šè·‘Llamaï¼Œä½†æ˜¯åœ¨MacOSä¸Šä½¿ç”¨Appleçš„metalè®¡ç®—å¹³å°è·‘èµ·æ¥å¤ªæ…¢ï¼Œæ¯”ä½¿ç”¨CPUè¿˜æ…¢ã€‚
æ‰€ä»¥å°±æƒ³ä½¿ç”¨AMDè‡ªå·±çš„è®¡ç®—å¹³å° `ROCm` ï¼Œå‘ç°åœ¨ `ROCm` ä¹Ÿå·²ç»æ¯”è¾ƒå®Œå–„äº†ï¼Œè¿˜æ”¯æŒäº†Windowsç³»ç»Ÿã€‚
ä½†æ˜¯æˆ‘é€‰æ‹©å®‰è£… `Ubuntu 24.04 LTS`ï¼Œæ¯•ç«Ÿä¸€å¼€å§‹å°±æ”¯æŒLinuxçš„ï¼Œä¼°è®¡ä¼˜åŒ–ä¼šå¥½äº›ã€‚

## **ROCmå®‰è£…**

ROCmæ”¯æŒä»¥ä¸‹linuxç³»ç»Ÿå’Œå†…æ ¸ï¼Œæœ€å¥½å®‰è£…å®˜æ–¹çš„æ¥ã€‚æœ¬æ¥æƒ³ç”¨debiançš„ï¼Œè¿˜æ˜¯åˆ«ç»™è‡ªå·±æ‰¾äº‹åšäº†ğŸ˜„

| Operating system | Kernel | Support |
|----|----|----|
| Ubuntu 24.04 | 6.8 \[GA\] | âœ… |
| Ubuntu 22.04.5 | 5.15 \[GA\], 6.8 \[HWE\] | âœ…  |
| Ubuntu 22.04.4 | 5.15 \[GA\], 6.5 \[HWE\] | âœ… |
| RHEL 9.4 | 5.14.0 | âœ… |
| RHEL 9.3 | 5.14.0 | âœ… |
| RHEL 8.10 | 4.18.0 | âœ… |
| RHEL 8.9 | 4.18.0 | âœ… |
| SLES 15 SP6 | 6.4.0 | âœ… |
| SLES 15 SP5 | 5.14.21 | âœ… |
| Oracle Linux 8.9 | 5.15.0 | âœ…  |

æˆ‘è¿™é‡Œé€‰æ‹©`Ubuntu 24.04 TLS` ï¼Œæ ¹æ®å®˜æ–¹æ–‡æ¡£å®‰è£…å‘½ä»¤å¦‚ä¸‹

```bash
sudo apt update
sudo apt install "linux-headers-$(uname -r)" "linux-modules-extra-$(uname -r)"
sudo usermod -a -G render,video $LOGNAME # Add the current user to the render and video groups
wget https://repo.radeon.com/amdgpu-install/6.2/ubuntu/noble/amdgpu-install_6.2.60200-1_all.deb
sudo apt install ./amdgpu-install_6.2.60200-1_all.deb
sudo apt update
sudo apt install amdgpu-dkms rocm
```

## **ä½¿ç”¨Llama.cpp**

`llama.cpp`åœ¨Githubä¸Šä¸‹è½½çš„é¢„ç¼–è¯‘æ–‡ä»¶åªæ”¯æŒCPUè¿è¡Œã€‚æˆ‘æ˜¯è¦ç”¨ `ROCm` æ¥åŠ é€Ÿï¼Œéœ€è¦è‡ªå·±ç¼–è¯‘ä¸€ä¸‹ï¼Œä¹Ÿæ¯”è¾ƒç®€å•ï¼Œè¯¦è§æ–‡æ¡£ï¼š<https://github.com/ggerganov/llama.cpp/blob/master/docs/build.md>

```bash
git clone https://github.com/ggerganov/llama.cpp
cd llama.cpp

make GGML_HIPBLAS=1
```

æˆ‘è¿™é‡Œä½¿ç”¨çš„Llama3.1-8Bæ¨¡å‹ï¼ˆ[Meta-Llama-3.1-8B-Instruct.Q8_0.gguf](https://huggingface.co/QuantFactory/Meta-Llama-3.1-8B-Instruct-GGUF)ï¼‰

```bash
./llama-server --host 0.0.0.0  -c 4096 -ngl 999 -m models/Meta-Llama-3.1-8B-Instruct.Q8_0.gguf
```

## **ä½¿ç”¨Ollama**

Ollamaå®‰è£…ç›´æ¥æ”¯æŒROCmï¼Œå®‰è£…å‘½ä»¤å¦‚ä¸‹

```bash
curl -fsSL https://ollama.com/install.sh | sh
```

è¾“å‡ºå¯ä»¥çœ‹åˆ°`Compatible AMD GPU ROCm library detected at /opt/rocm`ï¼Œè¯´æ˜å¯ä»¥ä½¿ç”¨`ROCm`

```
>>> Installing ollama to /usr/local
>>> Downloading Linux amd64 CLI
######################################################################## 100.0%  
>>> Making ollama accessible in the PATH in /usr/local/bin
>>> Creating ollama user...
>>> Adding ollama user to render group...
>>> Adding ollama user to video group...
>>> Adding current user to ollama group...
>>> Creating ollama systemd service...
>>> Enabling and starting ollama service...
Created symlink /etc/systemd/system/default.target.wants/ollama.service â†’ /etc/systemd/system/ollama.service.
>>> Compatible AMD GPU ROCm library detected at /opt/rocm
>>> The Ollama API is now available at 127.0.0.1:11434.
>>> Install complete. Run "ollama" from the command line.
```

æ‹‰å– `llama3.1` æ¨¡å‹

```bash
ollama pull llama3.1
```

è¿è¡Œ `llama3.1` 

```bash
ollama pull llama3.1
```

## **éªŒè¯æ˜¯å¦GPUåŠ é€Ÿ**

ROCmä½¿ç”¨ `rocm-smi` å‘½ä»¤æ¥æŸ¥çœ‹GPUçš„çŠ¶æ€ï¼Œç±»ä¼¼äºCUDAçš„ `nvidia-smi`

![](/assets/images/post/æˆªå±2024-08-23 15.58.10.png)

çœ‹åˆ°GPUçš„å ç”¨è¿˜æ˜¯æŒºé«˜çš„ï¼Œè¯´æ˜å·²ç»ç”¨åˆ°GPUåŠ é€Ÿäº†ï¼ŒåŒæ—¶ä¹Ÿå¯ä»¥çœ‹çœ‹CPUå ç”¨ï¼Œæ­£å¸¸ç”¨äº†GPUè®¡ç®—çš„è¯CPUå ç”¨å°±ç›¸å¯¹è¾ƒä½ã€‚

## **å‚è€ƒé“¾æ¥**

* <https://rocm.docs.amd.com/projects/install-on-linux/en/latest/install/quick-start.html>
* <https://github.com/ggerganov/llama.cpp/blob/master/docs/build.md>
* <https://blog.lyric.im/p/using-llamacpp-to-run-llama-2-using-amd-radeon-rx-6900-for-gpu-acceleration>
